{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029718,
     "end_time": "2020-10-26T12:46:41.276296",
     "exception": false,
     "start_time": "2020-10-26T12:46:41.246578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://whatcar.vn/media/2018/09/car-lot-940x470.jpg\"/>\n",
    "\n",
    "## Прогнозирование стоимости автомобиля по характеристикам\n",
    "*Этот Ноутбук является Примером/Шаблоном (Baseline) к этому соревнованию и не служит готовым решением!*   \n",
    "Вы можете использовать его как основу для построения своего решения.\n",
    "\n",
    "\n",
    "> **baseline** создается больше как шаблон, где можно посмотреть как происходит обращение с входящими данными и что нужно получить на выходе. При этом МЛ начинка может быть достаточно простой. Это помогает быстрее приступить к самому МЛ, а не тратить ценное время на чисто инженерные задачи. \n",
    "Также baseline является хорошей опорной точкой по метрике. Если твое решение хуже baseline - ты явно делаешь что-то не то и стоит попробовать другой путь) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028027,
     "end_time": "2020-10-26T12:46:41.334278",
     "exception": false,
     "start_time": "2020-10-26T12:46:41.306251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Помним, что по условию соревнования, нам нужно самостоятельно собрать обучающий датасет. В этом ноутбуке мы не будем рассматривать сбор данных. Предположим, что мы уже все собрали и просто подключили свой датасет через \"Add Data\", чтобы приступить к самому ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom fake_useragent import UserAgent \\nfrom bs4 import BeautifulSoup    \\nimport requests  \\nimport re\\nimport time\\nimport pandas as pd\\nimport numpy as np\\nimport itertools\\nfrom joblib import Parallel, delayed\\nfrom tqdm.notebook import tqdm\\n\\n\\n\\n\\n# Функция по извлечению данных со страницы объявления в словарь data_dict\\ndef parsing_page_one_ad(url):\\n\\n    response = requests.get(url, headers={\\'User-Agent\\': UserAgent().chrome})    \\n    response.encoding =\\'utf8\\'   \\n    \\n    # Теперь создадим объект BeautifulSoup, указывая html парсер    \\n    page = BeautifulSoup(response.text, \\'html.parser\\')\\n    data_dict = {}\\n\\n    data_dict[\\'car_url\\'] = url\\n    data_dict[\\'parsing_unixtime\\'] = int(time.time())\\n\\n\\n     # в разделах script ищем вхождение \\'complectation\":{\"id\"\\'\\n    for script in page.find_all(\"script\"):\\n        if \\'complectation\":{\"id\"\\' in str(script):\\n            a = str(script)  # присваиваем a содержимое скрипта как строку\\n    # в a  ищем \\'complectation\":\\' и содержимое между {}. Отсекаем начало, оставляя только содержимое словаря\\n            data_dict[\\'complectation_dict\\'] = re.search(r\\'complectation\":{\"id.*?}\\', a)[0][15:]\\n\\n        if \\'equipment\":{\\' in str(script):\\n            a = str(script)  # присваиваем a содержимое скрипта как строку\\n        # в a  ищем \\'equipment\":\\' и содержимое между {}. Отсекаем начало, оставляя только содержимое словаря\\n            data_dict[\\'equipment_dict\\'] = re.search(r\\'equipment\":{.*?}\\', a)[0][11:]\\n\\n        if \\'{\"mileage\":\\' in str(script):\\n            a = str(script)  # присваиваем a содержимое скрипта как строку\\n        # в a  ищем \\'{\"mileage\":\\' и содержимое между {}. Отсекаем начало, оставляя только содержимое словаря\\n            data_dict[\\'mileage\\'] = re.search(r\\'\"mileage\":\\\\d*\\', a)[0][10:]\\n\\n        if \\'\"model_info\":\\' in str(script):\\n            a = str(script)  # присваиваем a содержимое скрипта как строку\\n            data_dict[\\'model_info\\'] = re.search(r\\'\"model_info\":{.*?}\\', a)[0][13:]\\n            data_dict[\\'model_name\\'] = re.search(r\\'model_info\":{\"code\":\".*?\"\\', a)[0][20:].strip(\\'\"\\')\\n\\n        if \\'super_gen\":{\\' in str(script):\\n            a = str(script)  # присваиваем a содержимое скрипта как строку\\n            data_dict[\\'super_gen\\'] = re.search(r\\'super_gen\":{.*?}\\', a)[0][11:] \\n\\n        if \\'vendor\":\"\\' in str(script):\\n            a = str(script)  # присваиваем a содержимое скрипта как строку\\n            data_dict[\\'vendor\\'] = re.search(r\\'vendor\":\".*?\"\\', a)[0][9:].strip(\\'\"\\')\\n\\n\\n    for tag in page.find_all(\\'div\\'):\\n        if tag.get(\"title\") == \"Идентификатор объявления\":\\n            data_dict[\\'sell_id\\'] = re.search(r\\'\\\\d+\\', tag.text)[0]\\n\\n\\n    for tag in page.find_all(\"meta\"):\\n        if tag.get(\"itemprop\") == \"bodyType\":\\n            data_dict[\\'bodyType\\'] = tag.get(\"content\")\\n\\n        if tag.get(\"itemprop\") == \"brand\":\\n            data_dict[\\'brand\\'] = tag.get(\"content\")\\n\\n        if tag.get(\"itemprop\") == \"color\":\\n            data_dict[\\'color\\'] = tag.get(\"content\")\\n\\n        if tag.get(\"itemprop\") == \"description\":\\n            data_dict[\\'description\\'] = tag.get(\"content\")\\n\\n        if tag.get(\"itemprop\") == \"engineDisplacement\":\\n            data_dict[\\'engineDisplacement\\'] = tag.get(\"content\")\\n\\n        if tag.get(\"itemprop\") == \"enginePower\":\\n            data_dict[\\'enginePower\\'] = tag.get(\"content\")\\n\\n        if tag.get(\"itemprop\") == \"fuelType\":\\n            data_dict[\\'fuelType\\'] = tag.get(\"content\")\\n\\n        if tag.get(\"itemprop\") == \"modelDate\":\\n            data_dict[\\'modelDate\\'] = tag.get(\"content\")\\n\\n        if tag.get(\"itemprop\") == \"name\":\\n            data_dict[\\'name\\'] = tag.get(\"content\")\\n\\n        if tag.get(\"itemprop\") == \"numberOfDoors\":\\n            data_dict[\\'numberOfDoors\\'] = tag.get(\"content\")\\n\\n        if tag.get(\"itemprop\") == \"price\":\\n            data_dict[\\'price\\'] = tag.get(\"content\")\\n\\n        if tag.get(\"itemprop\") == \"priceCurrency\":\\n            data_dict[\\'priceCurrency\\'] = tag.get(\"content\")\\n\\n        if tag.get(\"itemprop\") == \"productionDate\":\\n            data_dict[\\'productionDate\\'] = tag.get(\"content\")\\n\\n        if tag.get(\"itemprop\") == \"vehicleConfiguration\":\\n            data_dict[\\'vehicleConfiguration\\'] = tag.get(\"content\")\\n\\n        if tag.get(\"itemprop\") == \"vehicleTransmission\":\\n            data_dict[\\'vehicleTransmission\\'] = tag.get(\"content\")\\n\\n\\n    span_CardInfoRow__cell = page.find_all(\\'span\\', {\\'class\\': \\'CardInfoRow__cell\\'})\\n\\n    for i,tag in enumerate (span_CardInfoRow__cell):\\n        if tag.text == \"Владельцы\":\\n            data_dict[\\'Владельцы\\'] = span_CardInfoRow__cell[i+1].text.replace(u\\'\\xa0\\', u\\' \\') # в  конце заменяем юникодовский пробел\\n\\n        if tag.text == \"Владение\":\\n            data_dict[\\'Владение\\'] = span_CardInfoRow__cell[i+1].text.replace(u\\'\\xa0\\', u\\' \\') # в  конце заменяем юникодовский пробел    \\n\\n        if tag.text == \"ПТС\":\\n            data_dict[\\'ПТС\\'] = span_CardInfoRow__cell[i+1].text.replace(u\\'\\xa0\\', u\\' \\') # в  конце заменяем юникодовский пробел    \\n\\n        if tag.text == \"Привод\":\\n            data_dict[\\'Привод\\'] = span_CardInfoRow__cell[i+1].text.replace(u\\'\\xa0\\', u\\' \\') # в  конце заменяем юникодовский пробел \\n\\n        if tag.text == \"Руль\":\\n            data_dict[\\'Руль\\'] = span_CardInfoRow__cell[i+1].text.replace(u\\'\\xa0\\', u\\' \\') # в  конце заменяем юникодовский пробел\\n\\n        if tag.text == \"Состояние\":\\n            data_dict[\\'Состояние\\'] = span_CardInfoRow__cell[i+1].text.replace(u\\'\\xa0\\', u\\' \\') # в  конце заменяем юникодовский пробел \\n\\n        if tag.text == \"Таможня\":\\n            data_dict[\\'Таможня\\'] = span_CardInfoRow__cell[i+1].text.replace(u\\'\\xa0\\', u\\' \\') # в  конце заменяем юникодовский пробел\\n\\n    return data_dict\\n\\n    \\n# Функция по созданию списка ссылок links_list  на объявления о продаже автомобилей  \\ndef extraction_links(url):\\n    links_list =[] \\n    response = requests.get(url, headers={\\'User-Agent\\': UserAgent().chrome})  \\n    response.encoding =\\'utf8\\'\\n    page = BeautifulSoup(response.text, \\'html.parser\\') \\n    links = page.find_all(\\'a\\', class_=\\'Link ListingItemTitle-module__link\\')\\n    \\n    for link in links:\\n        links_list.append(link.get(\"href\"))\\n    return links_list\\n    \\n    \\n    \\n    \\n    \\ndf = pd.DataFrame() # инициализируем итоговый датафрейм \\n\\nurl_link_list = [] # список страниц по годам и номерам от 1 до 99\\n\\nranges = [range(2006, 2011), range(1, 100)] # указываем года и диапазон страниц, которые будем парсить \\n\\n# index[0] - year, index[1] - page \\nfor index in itertools.product(*ranges):\\n    # формируем ссылки страницы со списками объявлений\\n    на  = (f\"https://auto.ru/moskva/cars/{index[0]}-year/all/?output_type=table&page={index[1]}\")\\n    url_link_list.append(url_links) # заносим их в список\\n    \\nlinks_list = [] # список списков ссылок на объявления c одной страницы таблицы объявлений\\n\\n#for url_links in url_link_list:\\n# извлекаем в links_list список ссылок на объявления\\ntry:\\n        #links_list = extraction_links(url_links)\\n    links_list = Parallel(n_jobs = 2)(delayed(extraction_links)(url_links) for url_links in url_link_list)\\nexcept:\\n    pass \\n\\nads_dict_list = [] # список словарей содержимого объявлений\\n\\nfor links in links_list:\\n    try:\\n        ads_dict_list = Parallel(n_jobs = 2)(delayed(parsing_page_one_ad)(ad_url) for ad_url in links)\\n    except:\\n        pass\\n    \\n    for ad in ads_dict_list:\\n        try:\\n            df = df.append(ad, ignore_index=True)\\n        except:\\n            pass\\n\\ndf.to_csv(\\'_auto_ru_XXXX-XXXX.csv\\', encoding = \\'utf-8\\', index=False) # записываем содержимое датафрейма в файл\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from fake_useragent import UserAgent \n",
    "from bs4 import BeautifulSoup    \n",
    "import requests  \n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Функция по извлечению данных со страницы объявления в словарь data_dict\n",
    "def parsing_page_one_ad(url):\n",
    "\n",
    "    response = requests.get(url, headers={'User-Agent': UserAgent().chrome})    \n",
    "    response.encoding ='utf8'   \n",
    "    \n",
    "    # Теперь создадим объект BeautifulSoup, указывая html парсер    \n",
    "    page = BeautifulSoup(response.text, 'html.parser')\n",
    "    data_dict = {}\n",
    "\n",
    "    data_dict['car_url'] = url\n",
    "    data_dict['parsing_unixtime'] = int(time.time())\n",
    "\n",
    "\n",
    "     # в разделах script ищем вхождение 'complectation\":{\"id\"'\n",
    "    for script in page.find_all(\"script\"):\n",
    "        if 'complectation\":{\"id\"' in str(script):\n",
    "            a = str(script)  # присваиваем a содержимое скрипта как строку\n",
    "    # в a  ищем 'complectation\":' и содержимое между {}. Отсекаем начало, оставляя только содержимое словаря\n",
    "            data_dict['complectation_dict'] = re.search(r'complectation\":{\"id.*?}', a)[0][15:]\n",
    "\n",
    "        if 'equipment\":{' in str(script):\n",
    "            a = str(script)  # присваиваем a содержимое скрипта как строку\n",
    "        # в a  ищем 'equipment\":' и содержимое между {}. Отсекаем начало, оставляя только содержимое словаря\n",
    "            data_dict['equipment_dict'] = re.search(r'equipment\":{.*?}', a)[0][11:]\n",
    "\n",
    "        if '{\"mileage\":' in str(script):\n",
    "            a = str(script)  # присваиваем a содержимое скрипта как строку\n",
    "        # в a  ищем '{\"mileage\":' и содержимое между {}. Отсекаем начало, оставляя только содержимое словаря\n",
    "            data_dict['mileage'] = re.search(r'\"mileage\":\\d*', a)[0][10:]\n",
    "\n",
    "        if '\"model_info\":' in str(script):\n",
    "            a = str(script)  # присваиваем a содержимое скрипта как строку\n",
    "            data_dict['model_info'] = re.search(r'\"model_info\":{.*?}', a)[0][13:]\n",
    "            data_dict['model_name'] = re.search(r'model_info\":{\"code\":\".*?\"', a)[0][20:].strip('\"')\n",
    "\n",
    "        if 'super_gen\":{' in str(script):\n",
    "            a = str(script)  # присваиваем a содержимое скрипта как строку\n",
    "            data_dict['super_gen'] = re.search(r'super_gen\":{.*?}', a)[0][11:] \n",
    "\n",
    "        if 'vendor\":\"' in str(script):\n",
    "            a = str(script)  # присваиваем a содержимое скрипта как строку\n",
    "            data_dict['vendor'] = re.search(r'vendor\":\".*?\"', a)[0][9:].strip('\"')\n",
    "\n",
    "\n",
    "    for tag in page.find_all('div'):\n",
    "        if tag.get(\"title\") == \"Идентификатор объявления\":\n",
    "            data_dict['sell_id'] = re.search(r'\\d+', tag.text)[0]\n",
    "\n",
    "\n",
    "    for tag in page.find_all(\"meta\"):\n",
    "        if tag.get(\"itemprop\") == \"bodyType\":\n",
    "            data_dict['bodyType'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"brand\":\n",
    "            data_dict['brand'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"color\":\n",
    "            data_dict['color'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"description\":\n",
    "            data_dict['description'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"engineDisplacement\":\n",
    "            data_dict['engineDisplacement'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"enginePower\":\n",
    "            data_dict['enginePower'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"fuelType\":\n",
    "            data_dict['fuelType'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"modelDate\":\n",
    "            data_dict['modelDate'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"name\":\n",
    "            data_dict['name'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"numberOfDoors\":\n",
    "            data_dict['numberOfDoors'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"price\":\n",
    "            data_dict['price'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"priceCurrency\":\n",
    "            data_dict['priceCurrency'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"productionDate\":\n",
    "            data_dict['productionDate'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"vehicleConfiguration\":\n",
    "            data_dict['vehicleConfiguration'] = tag.get(\"content\")\n",
    "\n",
    "        if tag.get(\"itemprop\") == \"vehicleTransmission\":\n",
    "            data_dict['vehicleTransmission'] = tag.get(\"content\")\n",
    "\n",
    "\n",
    "    span_CardInfoRow__cell = page.find_all('span', {'class': 'CardInfoRow__cell'})\n",
    "\n",
    "    for i,tag in enumerate (span_CardInfoRow__cell):\n",
    "        if tag.text == \"Владельцы\":\n",
    "            data_dict['Владельцы'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел\n",
    "\n",
    "        if tag.text == \"Владение\":\n",
    "            data_dict['Владение'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел    \n",
    "\n",
    "        if tag.text == \"ПТС\":\n",
    "            data_dict['ПТС'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел    \n",
    "\n",
    "        if tag.text == \"Привод\":\n",
    "            data_dict['Привод'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел \n",
    "\n",
    "        if tag.text == \"Руль\":\n",
    "            data_dict['Руль'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел\n",
    "\n",
    "        if tag.text == \"Состояние\":\n",
    "            data_dict['Состояние'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел \n",
    "\n",
    "        if tag.text == \"Таможня\":\n",
    "            data_dict['Таможня'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "    \n",
    "# Функция по созданию списка ссылок links_list  на объявления о продаже автомобилей  \n",
    "def extraction_links(url):\n",
    "    links_list =[] \n",
    "    response = requests.get(url, headers={'User-Agent': UserAgent().chrome})  \n",
    "    response.encoding ='utf8'\n",
    "    page = BeautifulSoup(response.text, 'html.parser') \n",
    "    links = page.find_all('a', class_='Link ListingItemTitle-module__link')\n",
    "    \n",
    "    for link in links:\n",
    "        links_list.append(link.get(\"href\"))\n",
    "    return links_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "df = pd.DataFrame() # инициализируем итоговый датафрейм \n",
    "\n",
    "url_link_list = [] # список страниц по годам и номерам от 1 до 99\n",
    "\n",
    "ranges = [range(2006, 2011), range(1, 100)] # указываем года и диапазон страниц, которые будем парсить \n",
    "\n",
    "# index[0] - year, index[1] - page \n",
    "for index in itertools.product(*ranges):\n",
    "    # формируем ссылки страницы со списками объявлений\n",
    "    на  = (f\"https://auto.ru/moskva/cars/{index[0]}-year/all/?output_type=table&page={index[1]}\")\n",
    "    url_link_list.append(url_links) # заносим их в список\n",
    "    \n",
    "links_list = [] # список списков ссылок на объявления c одной страницы таблицы объявлений\n",
    "\n",
    "#for url_links in url_link_list:\n",
    "# извлекаем в links_list список ссылок на объявления\n",
    "try:\n",
    "        #links_list = extraction_links(url_links)\n",
    "    links_list = Parallel(n_jobs = 2)(delayed(extraction_links)(url_links) for url_links in url_link_list)\n",
    "except:\n",
    "    pass \n",
    "\n",
    "ads_dict_list = [] # список словарей содержимого объявлений\n",
    "\n",
    "for links in links_list:\n",
    "    try:\n",
    "        ads_dict_list = Parallel(n_jobs = 2)(delayed(parsing_page_one_ad)(ad_url) for ad_url in links)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for ad in ads_dict_list:\n",
    "        try:\n",
    "            df = df.append(ad, ignore_index=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "df.to_csv('_auto_ru_XXXX-XXXX.csv', encoding = 'utf-8', index=False) # записываем содержимое датафрейма в файл\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nimport pandas as pd\\nimport numpy as np\\n\\ndf = pd.DataFrame()\\nlist_file = os.listdir(path=\".\") # получение списка файлов в папке\\n\\nfor file in list_file:\\n    if \\'.csv\\' in file: # если у файла расширение .csv, то читаем его как DF\\n        df_temp = pd.read_csv(file)\\n        df = pd.concat([df, df_temp], ignore_index=True)\\n        \\ndf = df.drop_duplicates(subset=[\\'car_url\\']) # удаление дубликатов по URL объявления\\n\\ndf = df.replace(\\'{}\\',  None) # замена пустых словарей на NaN\\ndf[\\'mileage\\'] = df[\\'mileage\\'].apply(lambda x: int(x) if type(x) == str else x) # приведение \\'mileage\\' к числовму виду\\ndf = df.replace(np.nan,  None)\\n\\ndf.to_csv(\\'_auto_ru_23012021.csv\\', encoding = \\'utf-8\\', index=False)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame()\n",
    "list_file = os.listdir(path=\".\") # получение списка файлов в папке\n",
    "\n",
    "for file in list_file:\n",
    "    if '.csv' in file: # если у файла расширение .csv, то читаем его как DF\n",
    "        df_temp = pd.read_csv(file)\n",
    "        df = pd.concat([df, df_temp], ignore_index=True)\n",
    "        \n",
    "df = df.drop_duplicates(subset=['car_url']) # удаление дубликатов по URL объявления\n",
    "\n",
    "df = df.replace('{}',  None) # замена пустых словарей на NaN\n",
    "df['mileage'] = df['mileage'].apply(lambda x: int(x) if type(x) == str else x) # приведение 'mileage' к числовму виду\n",
    "df = df.replace(np.nan,  None)\n",
    "\n",
    "df.to_csv('_auto_ru_23012021.csv', encoding = 'utf-8', index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:41.400302Z",
     "iopub.status.busy": "2020-10-26T12:46:41.399317Z",
     "iopub.status.idle": "2020-10-26T12:46:42.581426Z",
     "shell.execute_reply": "2020-10-26T12:46:42.580431Z"
    },
    "papermill": {
     "duration": 1.219772,
     "end_time": "2020-10-26T12:46:42.581597",
     "exception": false,
     "start_time": "2020-10-26T12:46:41.361825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:42.646795Z",
     "iopub.status.busy": "2020-10-26T12:46:42.645765Z",
     "iopub.status.idle": "2020-10-26T12:46:42.649793Z",
     "shell.execute_reply": "2020-10-26T12:46:42.650407Z"
    },
    "papermill": {
     "duration": 0.040034,
     "end_time": "2020-10-26T12:46:42.650603",
     "exception": false,
     "start_time": "2020-10-26T12:46:42.610569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python       : 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]\n",
      "Numpy        : 1.19.2\n"
     ]
    }
   ],
   "source": [
    "print('Python       :', sys.version.split('\\n')[0])\n",
    "print('Numpy        :', np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:42.716039Z",
     "iopub.status.busy": "2020-10-26T12:46:42.715184Z",
     "iopub.status.idle": "2020-10-26T12:46:47.852433Z",
     "shell.execute_reply": "2020-10-26T12:46:47.851661Z"
    },
    "papermill": {
     "duration": 5.172536,
     "end_time": "2020-10-26T12:46:47.852593",
     "exception": false,
     "start_time": "2020-10-26T12:46:42.680057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Could not generate requirement for distribution -cikit-learn 0.22.1 (c:\\programdata\\anaconda3\\lib\\site-packages): Parse error at \"'-cikit-l'\": Expected W:(abcd...)\n"
     ]
    }
   ],
   "source": [
    "# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:47.919419Z",
     "iopub.status.busy": "2020-10-26T12:46:47.918168Z",
     "iopub.status.idle": "2020-10-26T12:46:47.922267Z",
     "shell.execute_reply": "2020-10-26T12:46:47.921365Z"
    },
    "papermill": {
     "duration": 0.039842,
     "end_time": "2020-10-26T12:46:47.922434",
     "exception": false,
     "start_time": "2020-10-26T12:46:47.882592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_pred-y_true)/y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028837,
     "end_time": "2020-10-26T12:46:47.981435",
     "exception": false,
     "start_time": "2020-10-26T12:46:47.952598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:48.05046Z",
     "iopub.status.busy": "2020-10-26T12:46:48.049412Z",
     "iopub.status.idle": "2020-10-26T12:46:48.052578Z",
     "shell.execute_reply": "2020-10-26T12:46:48.051917Z"
    },
    "papermill": {
     "duration": 0.039969,
     "end_time": "2020-10-26T12:46:48.052728",
     "exception": false,
     "start_time": "2020-10-26T12:46:48.012759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VERSION    = 16\n",
    "DIR_TRAIN  = '../input/parsing-all-moscow-auto-ru-09-09-2020/' # подключил к ноутбуку внешний датасет\n",
    "#DIR_TRAIN  = '../input/auto-ru-moskva-23-01-2021/' # подключил к ноутбуку внешний датасет\n",
    "DIR_TEST   = '../input/sf-dst-car-price-prediction/'\n",
    "VAL_SIZE   = 0.20   # 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030254,
     "end_time": "2020-10-26T12:46:48.112586",
     "exception": false,
     "start_time": "2020-10-26T12:46:48.082332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:48.179769Z",
     "iopub.status.busy": "2020-10-26T12:46:48.178918Z",
     "iopub.status.idle": "2020-10-26T12:46:48.924574Z",
     "shell.execute_reply": "2020-10-26T12:46:48.925184Z"
    },
    "papermill": {
     "duration": 0.783211,
     "end_time": "2020-10-26T12:46:48.925418",
     "exception": false,
     "start_time": "2020-10-26T12:46:48.142207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"ls\" не является внутренней или внешней\n",
      "командой, исполняемой программой или пакетным файлом.\n"
     ]
    }
   ],
   "source": [
    "!ls '../input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:49.007668Z",
     "iopub.status.busy": "2020-10-26T12:46:49.006762Z",
     "iopub.status.idle": "2020-10-26T12:47:02.121152Z",
     "shell.execute_reply": "2020-10-26T12:47:02.120434Z"
    },
    "papermill": {
     "duration": 13.16556,
     "end_time": "2020-10-26T12:47:02.12133",
     "exception": false,
     "start_time": "2020-10-26T12:46:48.95577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/parsing-all-moscow-auto-ru-09-09-2020/all_auto_ru_09_09_2020.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8edcdb0a5fe0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDIR_TRAIN\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'all_auto_ru_09_09_2020.csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# датасет для обучения модели\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDIR_TEST\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msample_submission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDIR_TEST\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'sample_submission.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#train = pd.read_csv(DIR_TRAIN+'auto_ru_moskva_23_01_2021.csv') # датасет для обучения модели\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/parsing-all-moscow-auto-ru-09-09-2020/all_auto_ru_09_09_2020.csv'"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(DIR_TRAIN+'all_auto_ru_09_09_2020.csv') # датасет для обучения модели\n",
    "test = pd.read_csv(DIR_TEST+'test.csv')\n",
    "sample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')\n",
    "\n",
    "#train = pd.read_csv(DIR_TRAIN+'auto_ru_moskva_23_01_2021.csv') # датасет для обучения модели\n",
    "#test = pd.read_csv(DIR_TEST+'test.csv')\n",
    "#sample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:02.22557Z",
     "iopub.status.busy": "2020-10-26T12:47:02.21916Z",
     "iopub.status.idle": "2020-10-26T12:47:02.245921Z",
     "shell.execute_reply": "2020-10-26T12:47:02.246559Z"
    },
    "papermill": {
     "duration": 0.09378,
     "end_time": "2020-10-26T12:47:02.246755",
     "exception": false,
     "start_time": "2020-10-26T12:47:02.152975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train[train['price']>3_000_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:02.317036Z",
     "iopub.status.busy": "2020-10-26T12:47:02.316251Z",
     "iopub.status.idle": "2020-10-26T12:47:02.50135Z",
     "shell.execute_reply": "2020-10-26T12:47:02.501985Z"
    },
    "papermill": {
     "duration": 0.22352,
     "end_time": "2020-10-26T12:47:02.502166",
     "exception": false,
     "start_time": "2020-10-26T12:47:02.278646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:02.599966Z",
     "iopub.status.busy": "2020-10-26T12:47:02.598892Z",
     "iopub.status.idle": "2020-10-26T12:47:02.604335Z",
     "shell.execute_reply": "2020-10-26T12:47:02.60353Z"
    },
    "papermill": {
     "duration": 0.069985,
     "end_time": "2020-10-26T12:47:02.604497",
     "exception": false,
     "start_time": "2020-10-26T12:47:02.534512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:02.7822Z",
     "iopub.status.busy": "2020-10-26T12:47:02.781391Z",
     "iopub.status.idle": "2020-10-26T12:47:02.797734Z",
     "shell.execute_reply": "2020-10-26T12:47:02.798395Z"
    },
    "papermill": {
     "duration": 0.160401,
     "end_time": "2020-10-26T12:47:02.798587",
     "exception": false,
     "start_time": "2020-10-26T12:47:02.638186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['image'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033402,
     "end_time": "2020-10-26T12:47:02.866506",
     "exception": false,
     "start_time": "2020-10-26T12:47:02.833104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:02.941177Z",
     "iopub.status.busy": "2020-10-26T12:47:02.94004Z",
     "iopub.status.idle": "2020-10-26T12:47:02.94372Z",
     "shell.execute_reply": "2020-10-26T12:47:02.943059Z"
    },
    "papermill": {
     "duration": 0.042812,
     "end_time": "2020-10-26T12:47:02.943868",
     "exception": false,
     "start_time": "2020-10-26T12:47:02.901056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:03.025049Z",
     "iopub.status.busy": "2020-10-26T12:47:03.024167Z",
     "iopub.status.idle": "2020-10-26T12:47:03.134429Z",
     "shell.execute_reply": "2020-10-26T12:47:03.133689Z"
    },
    "papermill": {
     "duration": 0.156124,
     "end_time": "2020-10-26T12:47:03.134605",
     "exception": false,
     "start_time": "2020-10-26T12:47:02.978481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.dropna(subset=['productionDate','mileage'], inplace=True)\n",
    "train.dropna(subset=['price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сформируем списки столбцов по группам исходя из типов признаков\n",
    "num_cols = ['mileage', 'modelDate', 'productionDate']\n",
    "#bin_cols =['Руль', 'Состояние', 'Таможня', 'ПТС'] \n",
    "bin_cols =['Руль', 'Состояние', 'ПТС'] \n",
    "category_cols = ['model_info', 'model_name', 'name', 'super_gen', 'complectation_dict', 'equipment_dict',  'bodyType', 'brand', 'color', 'fuelType', 'numberOfDoors', \n",
    "                 'priceCurrency',  'vehicleConfiguration', 'vehicleTransmission', 'vendor', 'Владельцы', 'Владение', 'Привод', 'engineDisplacement', 'enginePower']\n",
    "# 'priceCurrency' - тип валюты. В настоящее время у нас только рубли, но могут быть и др. варианты. Поэтому отнесем к категориальным данным "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:03.218827Z",
     "iopub.status.busy": "2020-10-26T12:47:03.21765Z",
     "iopub.status.idle": "2020-10-26T12:47:03.222821Z",
     "shell.execute_reply": "2020-10-26T12:47:03.223415Z"
    },
    "papermill": {
     "duration": 0.054414,
     "end_time": "2020-10-26T12:47:03.223614",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.1692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# для baseline просто возьму пару схожих признаков без полной обработки\n",
    "#columns = ['bodyType', 'brand', 'productionDate', 'engineDisplacement', 'mileage','Владельцы']\n",
    "y = train['price']\n",
    "train.drop(['price'], axis=1,inplace=True)\n",
    "df_train = train#[columns]\n",
    "df_test = test#[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033657,
     "end_time": "2020-10-26T12:47:03.29162",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.257963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:03.371409Z",
     "iopub.status.busy": "2020-10-26T12:47:03.370451Z",
     "iopub.status.idle": "2020-10-26T12:47:03.40603Z",
     "shell.execute_reply": "2020-10-26T12:47:03.405053Z"
    },
    "papermill": {
     "duration": 0.080223,
     "end_time": "2020-10-26T12:47:03.406196",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.325973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:03.489637Z",
     "iopub.status.busy": "2020-10-26T12:47:03.483022Z",
     "iopub.status.idle": "2020-10-26T12:47:03.549376Z",
     "shell.execute_reply": "2020-10-26T12:47:03.548539Z"
    },
    "papermill": {
     "duration": 0.10809,
     "end_time": "2020-10-26T12:47:03.549533",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.441443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for colum in ['bodyType', 'brand', 'engineDisplacement']:\n",
    "#    data[colum] = data[colum].astype('category').cat.codes\n",
    "for colum in category_cols:\n",
    "    data[colum] = data[colum].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['Таможня'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Состояние\"] = data[\"Состояние\"].fillna('Неизвестно')\n",
    "#data[\"Таможня\"] = data[\"Таможня\"].fillna('Растаможен')\n",
    "data[\"ПТС\"] = data[\"ПТС\"].fillna('Неизвестно')\n",
    "\n",
    "#data[bin_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"Владельцы\"] = data[\"Владельцы\"].str.replace(u'\\xa0', '')\n",
    "#label_encoder = LabelEncoder()\n",
    "#for column in columns:\n",
    "#data['Владельцы'] = label_encoder.fit_transform(data['Владельцы'])\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in bin_cols:\n",
    "    #print(column)\n",
    "    data[column] = label_encoder.fit_transform(data[column])\n",
    "    \n",
    "# убедимся в преобразовании    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:03.6352Z",
     "iopub.status.busy": "2020-10-26T12:47:03.633973Z",
     "iopub.status.idle": "2020-10-26T12:47:03.646722Z",
     "shell.execute_reply": "2020-10-26T12:47:03.645899Z"
    },
    "papermill": {
     "duration": 0.06183,
     "end_time": "2020-10-26T12:47:03.646867",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.585037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Удалим столбцы не несущие в себе параметры автомобиля, и не влиящие на предсказание цены, а так же те которые не успел обработать  \n",
    "data.drop(['car_url', 'parsing_unixtime', 'sell_id','Комплектация','Таможня','hidden','start_date','model'], axis=1,inplace=True)\n",
    "# В связи с отсутствие времени на обработку текста, также удалим 'description'\n",
    "data.drop(['description'], axis=1,inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols ={\"complectation_dict\",'equipment_dict', 'Владение'}\n",
    "for col in cols:\n",
    "    data[f'{col}_isNAN'] = pd.isna(data[col]).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:03.727044Z",
     "iopub.status.busy": "2020-10-26T12:47:03.725742Z",
     "iopub.status.idle": "2020-10-26T12:47:03.753844Z",
     "shell.execute_reply": "2020-10-26T12:47:03.753001Z"
    },
    "papermill": {
     "duration": 0.071275,
     "end_time": "2020-10-26T12:47:03.754",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.682725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data.query('sample == 1').drop(['sample'], axis=1)\n",
    "X_sub = data.query('sample == 0').drop(['sample'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035737,
     "end_time": "2020-10-26T12:47:03.826552",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.790815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:03.90948Z",
     "iopub.status.busy": "2020-10-26T12:47:03.908518Z",
     "iopub.status.idle": "2020-10-26T12:47:03.923409Z",
     "shell.execute_reply": "2020-10-26T12:47:03.922602Z"
    },
    "papermill": {
     "duration": 0.059208,
     "end_time": "2020-10-26T12:47:03.923564",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.864356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Создадим \"наивную\" модель \n",
    "Эта модель будет предсказывать среднюю цену по модели двигателя (engineDisplacement). \n",
    "C ней будем сравнивать другие модели.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train = X_train.copy()\n",
    "tmp_train['price'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Находим median по экземплярам engineDisplacement в трейне и размечаем тест\n",
    "predict = X_test['engineDisplacement'].map(tmp_train.groupby('engineDisplacement')['price'].median())\n",
    "\n",
    "#оцениваем точность\n",
    "print(f\"Точность наивной модели по метрике MAPE: {(mape(y_test, predict.values))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037164,
     "end_time": "2020-10-26T12:47:03.997616",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.960452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# # Model 2 : CatBoost\n",
    "![](https://pbs.twimg.com/media/DP-jUCyXcAArRTo.png:large)   \n",
    "\n",
    "\n",
    "У нас в данных практически все признаки категориальные. Специально для работы с такими данными была создана очень удобная библиотека CatBoost от Яндекса. [https://catboost.ai](http://)     \n",
    "На данный момент **CatBoost является одной из лучших библиотек для табличных данных!**\n",
    "\n",
    "#### Полезные видео о CatBoost (на русском):\n",
    "* [Доклад про CatBoost](https://youtu.be/9ZrfErvm97M)\n",
    "* [Свежий Туториал от команды CatBoost (практическая часть)](https://youtu.be/wQt4kgAOgV0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035833,
     "end_time": "2020-10-26T12:47:04.149539",
     "exception": false,
     "start_time": "2020-10-26T12:47:04.113706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:04.256865Z",
     "iopub.status.busy": "2020-10-26T12:47:04.248328Z",
     "iopub.status.idle": "2020-10-26T12:48:12.17834Z",
     "shell.execute_reply": "2020-10-26T12:48:12.17762Z"
    },
    "papermill": {
     "duration": 67.991521,
     "end_time": "2020-10-26T12:48:12.178488",
     "exception": false,
     "start_time": "2020-10-26T12:47:04.186967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations = 5000,\n",
    "                          random_seed = RANDOM_SEED,\n",
    "                          eval_metric='MAPE',\n",
    "                          custom_metric=['R2', 'MAE'],\n",
    "                          silent=True,\n",
    "                         )\n",
    "model.fit(X_train, y_train,\n",
    "         #cat_features=cat_features_ids,\n",
    "         eval_set=(X_test, y_test),\n",
    "         verbose_eval=0,\n",
    "         use_best_model=True,\n",
    "         #plot=True\n",
    "         )\n",
    "\n",
    "model.save_model('catboost_single_model_baseline.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оцениваем точность\n",
    "predict = model.predict(X_test)\n",
    "print(f\"Точность модели по метрике MAPE: {(mape(y_test, predict))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.088891,
     "end_time": "2020-10-26T12:48:12.562943",
     "exception": false,
     "start_time": "2020-10-26T12:48:12.474052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Вот так просто со старта, даже не трогая сами данные и не подбирая настройки catboosta, получаем модель с уровнем ошибки в 18%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Traget\n",
    "Попробуем взять таргет в логорифм - это позволит уменьшить влияние выбросов на обучение модели (используем для этого np.log и np.exp).    \n",
    "В принциепе мы можем использовать любое приобразование на целевую переменную. Например деление на курс доллара, евро или гречки :) в дату сбора данных, смотрим дату парсинга в тесте в **parsing_unixtime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск наилучших параметров для CatBoostRegressor\n",
    "cbr = CatBoostRegressor()\n",
    "\n",
    "grid = {'learning_rate': [round(x,3) for x in np.linspace(start = 0.025, stop = 0.4, num = 40)],\n",
    "        'depth': [int(x) for x in np.linspace(start = 5, stop = 10, num = 5)],\n",
    "        'l2_leaf_reg': [int(x) for x in np.linspace(start = 1, stop = 5, num = 5)]}\n",
    "\n",
    "#grid_search_result = cbr.grid_search(grid, \n",
    "#                                       X=X_train, \n",
    "#                                       y=y_train, \n",
    "#                                       plot=False)\n",
    "#print(grid_search_result['params'])\n",
    "\n",
    "# {'depth': 10,'l2_leaf_reg': 2, 'learning_rate': 0.381} bestTest = 543125.899    bestIteration = 331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations = 330,\n",
    "                          learning_rate = 0.381,\n",
    "                          random_seed = RANDOM_SEED,\n",
    "                          eval_metric='MAPE',\n",
    "                          custom_metric=['R2', 'MAE'],\n",
    "                          depth = 10,\n",
    "                          l2_leaf_reg = 2)\n",
    "\n",
    "\n",
    "model.fit(X_train, np.log(y_train),\n",
    "         #cat_features=cat_features_ids,\n",
    "         eval_set=(X_test, np.log(y_test)),\n",
    "         verbose_eval=0,\n",
    "         use_best_model=True,\n",
    "         #plot=True\n",
    "         )\n",
    "\n",
    "model.save_model('catboost_single_model_2_baseline.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = np.exp(model.predict(X_test))\n",
    "#predict_submission = np.round((np.exp(model.predict(X_sub))-1)/1000) *1000\n",
    "predict_submission = np.exp(model.predict(X_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Точность модели по метрике MAPE: {(mape(y_test, predict_test))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим точность возросла до 13%, а что будет на ЛБ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.085876,
     "end_time": "2020-10-26T12:48:12.734207",
     "exception": false,
     "start_time": "2020-10-26T12:48:12.648331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:48:13.227584Z",
     "iopub.status.busy": "2020-10-26T12:48:13.226285Z",
     "iopub.status.idle": "2020-10-26T12:48:13.762529Z",
     "shell.execute_reply": "2020-10-26T12:48:13.763259Z"
    },
    "papermill": {
     "duration": 0.628302,
     "end_time": "2020-10-26T12:48:13.763488",
     "exception": false,
     "start_time": "2020-10-26T12:48:13.135186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission['price'] = predict_submission\n",
    "sample_submission.to_csv(f'submission_2_v{VERSION}.csv', index=False)\n",
    "#sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.083769,
     "end_time": "2020-10-26T12:48:13.930562",
     "exception": false,
     "start_time": "2020-10-26T12:48:13.846793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "В итоге получили **MAPE 27%** на ЛБ!\n",
    "\n",
    "Большая разница в ошибке может указывать на то что тест и трейн имеют различия по выборке или то что данные в трейне могли уже устареть и их нужно обновлять."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.087712,
     "end_time": "2020-10-26T12:48:14.104388",
     "exception": false,
     "start_time": "2020-10-26T12:48:14.016676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# What's next?\n",
    "Или что еще можно сделать, чтоб улучшить результат:\n",
    "\n",
    "* Спарсить свежие данные \n",
    "* Посмотреть, что можно извлечь из признаков или как еще можно обработать признаки\n",
    "* Сгенерировать новые признаки\n",
    "* Попробовать подобрать параметры модели\n",
    "* Попробовать другие алгоритмы и библиотеки ML\n",
    "* Сделать Ансамбль моделей, Blending, Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробный чек лист: https://docs.google.com/spreadsheets/d/1I_ErM3U0Cs7Rs1obyZbIEGtVn-H47pHNCi4xdDgUmXY/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.082055,
     "end_time": "2020-10-26T12:48:14.270602",
     "exception": false,
     "start_time": "2020-10-26T12:48:14.188547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.08168,
     "end_time": "2020-10-26T12:48:14.435554",
     "exception": false,
     "start_time": "2020-10-26T12:48:14.353874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.080788,
     "end_time": "2020-10-26T12:48:14.596978",
     "exception": false,
     "start_time": "2020-10-26T12:48:14.51619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
