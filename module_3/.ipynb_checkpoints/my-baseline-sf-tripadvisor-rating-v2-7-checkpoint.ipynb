{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.pata.org/wp-content/uploads/2014/09/TripAdvisor_Logo-300x119.png)\n",
    "# Predict TripAdvisor Rating\n",
    "## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor\n",
    "**По ходу задачи:**\n",
    "* Прокачаем работу с pandas\n",
    "* Научимся работать с Kaggle Notebooks\n",
    "* Поймем как делать предобработку различных данных\n",
    "* Научимся работать с пропущенными данными (Nan)\n",
    "* Познакомимся с различными видами кодирования признаков\n",
    "* Немного попробуем [Feature Engineering](https://ru.wikipedia.org/wiki/Конструирование_признаков) (генерировать новые признаки)\n",
    "* И совсем немного затронем ML\n",
    "* И многое другое...   \n",
    "\n",
    "\n",
    "\n",
    "### И самое важное, все это вы сможете сделать самостоятельно!\n",
    "\n",
    "*Этот Ноутбук являетсся Примером/Шаблоном к этому соревнованию (Baseline) и не служит готовым решением!*   \n",
    "Вы можете использовать его как основу для построения своего решения.\n",
    "\n",
    "> что такое baseline решение, зачем оно нужно и почему предоставлять baseline к соревнованию стало важным стандартом на kaggle и других площадках.   \n",
    "**baseline** создается больше как шаблон, где можно посмотреть как происходит обращение с входящими данными и что нужно получить на выходе. При этом МЛ начинка может быть достаточно простой, просто для примера. Это помогает быстрее приступить к самому МЛ, а не тратить ценное время на чисто инженерные задачи. \n",
    "Также baseline являеться хорошей опорной точкой по метрике. Если твое решение хуже baseline - ты явно делаешь что-то не то и стоит попробовать другой путь) \n",
    "\n",
    "В контексте нашего соревнования baseline идет с небольшими примерами того, что можно делать с данными, и с инструкцией, что делать дальше, чтобы улучшить результат.  Вообще готовым решением это сложно назвать, так как используются всего 2 самых простых признака (а остальные исключаются)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Загружаем специальный удобный инструмент для разделения датасета:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /kaggle/input/sf-dst-restaurant-rating//main_task.csv does not exist: '/kaggle/input/sf-dst-restaurant-rating//main_task.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7e98853660f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/kaggle/input/sf-dst-restaurant-rating/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/main_task.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'kaggle_task.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msample_submission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/sample_submission.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File /kaggle/input/sf-dst-restaurant-rating//main_task.csv does not exist: '/kaggle/input/sf-dst-restaurant-rating//main_task.csv'"
     ]
    }
   ],
   "source": [
    "DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\n",
    "df_train = pd.read_csv(DATA_DIR+'/main_task.csv')\n",
    "df_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\n",
    "sample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее по признакам:\n",
    "* City: Город \n",
    "* Cuisine Style: Кухня\n",
    "* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n",
    "* Price Range: Цены в ресторане в 3 категориях\n",
    "* Number of Reviews: Количество отзывов\n",
    "* Reviews: 2 последних отзыва и даты этих отзывов\n",
    "* URL_TA: страница ресторана на 'www.tripadvisor.com' \n",
    "* ID_TA: ID ресторана в TripAdvisor\n",
    "* Rating: Рейтинг ресторана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Reviews[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, большинство признаков у нас требует очистки и предварительной обработки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Prepping Data\n",
    "Обычно данные содержат в себе кучу мусора, который необходимо почистить, для того чтобы привести их в приемлемый формат. Чистка данных — это необходимый этап решения почти любой реальной задачи.   \n",
    "![](https://analyticsindiamag.com/wp-content/uploads/2018/01/data-cleaning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Обработка NAN \n",
    "У наличия пропусков могут быть разные причины, но пропуски нужно либо заполнить, либо исключить из набора полностью. Но с пропусками нужно быть внимательным, **даже отсутствие информации может быть важным признаком!**   \n",
    "По этому перед обработкой NAN лучше вынести информацию о наличии пропуска как отдельный признак "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для примера я возьму столбец Number of Reviews\n",
    "data['Number_of_Reviews_isNAN'] = pd.isna(data['Number of Reviews']).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Number_of_Reviews_isNAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Далее заполняем пропуски 0, вы можете попробовать заполнением средним или средним по городу и тд...\n",
    "data['Number of Reviews'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Обработка признаков\n",
    "Для начала посмотрим какие признаки у нас могут быть категориальными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие признаки можно считать категориальными?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для кодирования категориальных признаков есть множество подходов:\n",
    "* Label Encoding\n",
    "* One-Hot Encoding\n",
    "* Target Encoding\n",
    "* Hashing\n",
    "\n",
    "Выбор кодирования зависит от признака и выбраной модели.\n",
    "Не будем сейчас сильно погружаться в эту тематику, давайте посмотрим лучше пример с One-Hot Encoding:\n",
    "![](https://i.imgur.com/mtimFxh.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для One-Hot Encoding в pandas есть готовая функция - get_dummies. Особенно радует параметр dummy_na\n",
    "data = pd.get_dummies(data, columns=[ 'City',], dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Возьмем следующий признак \"Price Range\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price Range'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По описанию 'Price Range' это - Цены в ресторане.  \n",
    "Их можно поставить по возрастанию (значит это не категориальный признак). А это значит, что их можно заменить последовательными числами, например 1,2,3  \n",
    "*Попробуйте сделать обработку этого признака уже самостоятельно!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваша обработка 'Price Range'\n",
    "def change_Price_Range(line):    \n",
    "    if(line=='$'):\n",
    "        return 1\n",
    "    elif(line=='$$ - $$$'):\n",
    "        return 2\n",
    "    elif(line=='$$$$'):\n",
    "        return 3\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "data['Price Range'] = data['Price Range'].apply(change_Price_Range)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Для некоторых алгоритмов МЛ даже для не категориальных признаков можно применить One-Hot Encoding, и это может улучшить качество модели. Пробуйте разные подходы к кодированию признака - никто не знает заранее, что может взлететь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработать другие признаки вы должны самостоятельно!\n",
    "Для обработки других признаков вам возможно придется даже написать свою функцию, а может даже и не одну, но в этом и есть ваша практика в этом модуле!     \n",
    "Следуя подсказкам в модуле вы сможете более подробно узнать, как сделать эти приобразования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тут ваш код на обработку других признаков\n",
    "#Получаем да тут предыдущего отзыва\n",
    "def get_first_date_reviews(line):\n",
    "    line = str(line)\n",
    "    countsymbol = line.count('/')\n",
    "    if(countsymbol == 4):\n",
    "        line = line[-13:-3]\n",
    "    else:\n",
    "        line = np.nan\n",
    "    return line\n",
    "\n",
    "#Получаем да тут последнего отзыва\n",
    "def get_last_date_reviews(line):\n",
    "    line = str(line)\n",
    "    countsymbol = line.count('/')\n",
    "    if(countsymbol == 4):\n",
    "        line = line[-27:-17]\n",
    "        if(line.replace('/', '').isdecimal() == False):\n",
    "            line = np.nan\n",
    "    else:\n",
    "        line = np.nan\n",
    "    return line\n",
    "\n",
    "\n",
    "def get_count_rest_on_town(city, dict_count_rest):\n",
    "    return dict_count_rest[city]\n",
    "\n",
    "#Получаем количество стилей кухонь\n",
    "def filter_cuisine_style(line):\n",
    "    line = line.replace('[', '')\n",
    "    line = line.replace(']', '')\n",
    "    line = line.replace(\"'\", '')\n",
    "    if(line == 'Nothing'):\n",
    "        return 1\n",
    "    else:\n",
    "        return line.count(',')+1\n",
    "\n",
    "#Преобразовываем стили кухонь в строку с разделителяи\n",
    "def filter_cuisine_style2(line):    \n",
    "    line = line.replace('[', '')\n",
    "    line = line.replace(']', '')\n",
    "    line = line.replace(\"'\", '')\n",
    "    return line\n",
    "    \n",
    "#Получаем длину строки отзывов\n",
    "def get_lenght_reviews(line):\n",
    "    line = str(line)\n",
    "    if(len(line) < 10):\n",
    "        return 0\n",
    "    else:\n",
    "        find = line.find(']', 0, len(line)-1)\n",
    "        return find-3        \n",
    "\n",
    "# Отображение информации о колонке\n",
    "def show_info_column(dataframe, column):\n",
    "    display(dataframe[column].describe())\n",
    "    plt.hist(dataframe[column], bins=30)\n",
    "    plt.ylabel('Количество')\n",
    "    plt.xlabel(column)\n",
    "    # plt.title('Histogram');\n",
    "    plt.show()\n",
    "    # Нижняя граница выбросов\n",
    "    minimum_emission_limit = round(\n",
    "        dataframe[column].mean() - 3 * dataframe[column].std(), 0)\n",
    "    # Верхняя граница выбросов\n",
    "    maximum_emission_limit = round(\n",
    "        dataframe[column].mean() + 3 * dataframe[column].std(), 0)\n",
    "    # Количество выбросов\n",
    "    quantity_of_emissions = len(dataframe[round(\n",
    "        ((dataframe[column] - dataframe[column].mean()) / dataframe[column].std()).abs(), 0) > 3].index)\n",
    "    print('Границы выбросов', minimum_emission_limit, maximum_emission_limit)\n",
    "    display(sns.boxplot(data=dataframe[column]))\n",
    "    print('Количество выбросов', quantity_of_emissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cs10.pikabu.ru/post_img/2018/09/06/11/1536261023140110012.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA \n",
    "[Exploratory Data Analysis](https://ru.wikipedia.org/wiki/Разведочный_анализ_данных) - Анализ данных\n",
    "На этом этапе мы строим графики, ищем закономерности, аномалии, выбросы или связи между признаками.\n",
    "В общем цель этого этапа понять, что эти данные могут нам дать и как признаки могут быть взаимосвязаны между собой.\n",
    "Понимание изначальных признаков позволит сгенерировать новые, более сильные и, тем самым, сделать нашу модель лучше.\n",
    "![](https://miro.medium.com/max/2598/1*RXdMb7Uk6mGqWqPguHULaQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим распределение признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,7)\n",
    "df_train['Ranking'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас много ресторанов, которые не дотягивают и до 2500 места в своем городе, а что там по городам?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['City'].value_counts(ascending=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А кто-то говорил, что французы любят поесть=) Посмотрим, как изменится распределение в большом городе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Ranking'][df_train['City'] =='London'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на топ 10 городов\n",
    "for x in (df_train['City'].value_counts())[0:10].index:\n",
    "    df_train['Ranking'][df_train['City'] == x].hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что Ranking имеет нормальное распределение, просто в больших городах больше ресторанов, из-за мы этого имеем смещение.\n",
    "\n",
    ">Подумайте как из этого можно сделать признак для вашей модели. Я покажу вам пример, как визуализация помогает находить взаимосвязи. А далее действуйте без подсказок =) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим распределение целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Rating'].value_counts(ascending=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим распределение целевой переменной относительно признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Ranking'][df_train['Rating'] == 5].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Ranking'][df_train['Rating'] < 4].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### И один из моих любимых - [корреляция признаков](https://ru.wikipedia.org/wiki/Корреляция)\n",
    "На этом графике уже сейчас вы сможете заметить, как признаки связаны между собой и с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15,10)\n",
    "sns.heatmap(data.drop(['sample'], axis=1).corr(),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще благодаря визуализации в этом датасете можно узнать много интересных фактов, например:\n",
    "* где больше Пицерий в Мадриде или Лондоне?\n",
    "* в каком городе кухня ресторанов более разнообразна?\n",
    "\n",
    "придумайте свои вопрос и найдите на него ответ в данных)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Теперь, для удобства и воспроизводимости кода, завернем всю обработку в одну большую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# на всякий случай, заново подгружаем данные\n",
    "df_train = pd.read_csv(DATA_DIR+'/main_task.csv')\n",
    "df_test = pd.read_csv(DATA_DIR+'/kaggle_task.csv')\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_info_column(dataframe, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_data(df_input):\n",
    "    '''includes several functions to pre-process the predictor data.'''\n",
    "    \n",
    "    df_output = df_input.copy()\n",
    "    \n",
    "    # ################### 1. Предобработка ############################################################## \n",
    "    # убираем не нужные для модели признаки\n",
    "    df_output.drop(['Restaurant_id','ID_TA',], axis = 1, inplace=True)\n",
    "    \n",
    "    \n",
    "    # ################### 2. NAN ############################################################## \n",
    "    # Далее заполняем пропуски, вы можете попробовать заполнением средним или средним по городу и тд...\n",
    "    df_output['Number of Reviews'].fillna(0, inplace=True)\n",
    "    #df_output['Number of Reviews'].fillna(df_output['Number of Reviews'].mean(), inplace=True)\n",
    "    # тут ваш код по обработке NAN\n",
    "    # ....\n",
    "    \n",
    "    \n",
    "    # ################### 3. Encoding ############################################################## \n",
    "    # для One-Hot Encoding в pandas есть готовая функция - get_dummies. Особенно радует параметр dummy_na\n",
    "    df_output['City2']=df_output['City']\n",
    "    df_output = pd.get_dummies(df_output, columns=['City'], dummy_na=True)\n",
    "    # тут ваш код не Encoding фитчей\n",
    "    # ....\n",
    "    \n",
    "    #df_output = pd.get_dummies(df_output, columns=['Price Range'],dummy_na=True)\n",
    "    \n",
    "    # ################### 4. Feature Engineering ####################################################\n",
    "    # тут ваш код не генерацию новых фитчей\n",
    "    # ....\n",
    "    #Добавим колонку с количеством ресторанов в городе\n",
    "    dict_count_rest = df_output['City2'].value_counts().to_dict()\n",
    "    df_output['count_rest'] = df_output['City2'].apply(get_count_rest_on_town,args=[dict_count_rest])    \n",
    "    \n",
    "    #Добавим колонку с количеством кухонь в ресторане\n",
    "    df_output['Cuisine Style'] = df_output['Cuisine Style'].fillna('Nothing')\n",
    "    df_output['count_cuisine_style'] = df_output['Cuisine Style'].apply(filter_cuisine_style)\n",
    "    #df_output['Cuisine Style'] = df_output['Cuisine Style'].fillna('Nothing')    \n",
    "    \n",
    "    #Добавим новый думми фактор Cuisine Style\n",
    "    df_output['Cuisine Style2'] = df_output['Cuisine Style'].apply(filter_cuisine_style2)\n",
    "    df_output2 = df_output['Cuisine Style2'].str.get_dummies(',')        \n",
    "    df_output = pd.concat([df_output, df_output2],sort=False,axis=1)\n",
    "\n",
    "    #Добавим колонку с текущей датой для удобства вычислений\n",
    "    d = datetime.date.today()\n",
    "    df_output['datetime_today'] = d\n",
    "    #Парсим колонку Reviews для того чтобы получить дату предыдущего отзыва \n",
    "    df_output['Reviews_first_date'] = df_output['Reviews'].apply(get_first_date_reviews)\n",
    "    #Парсим колонку Reviews для того чтобы получить дату последнего отзыва\n",
    "    df_output['Reviews_last_date'] = df_output['Reviews'].apply(get_last_date_reviews)\n",
    "    #Преобразовывем тип полученных значений к типу дата \n",
    "    df_output['Reviews_first_date'] = pd.to_datetime(df_output['Reviews_first_date'])\n",
    "    #Преобразовывем тип полученных значений к типу дата\n",
    "    df_output['Reviews_last_date']  = pd.to_datetime(df_output['Reviews_last_date'])\n",
    "    #Преобразовывем тип полученных значений к типу дата\n",
    "    df_output['datetime_today']     = pd.to_datetime(df_output['datetime_today'])\n",
    "    \n",
    "    #Добавим новый фактор разница дней между текущей датой и последним отзывом\n",
    "    df_output['delta_today_reviews_last_date'] = (df_output['datetime_today'] - df_output['Reviews_last_date']).dt.days\n",
    "    #Добавим новый фактор разница дней между отзывами\n",
    "    df_output['delta_last_date_first_date'] = (df_output['Reviews_last_date'] - df_output['Reviews_first_date']).dt.days        \n",
    "    #Добавим новый фактор количество кухонных стилей в ресторане\n",
    "    df_output['count_cuisine_style'] = df_output['Cuisine Style'].apply(filter_cuisine_style)\n",
    "    \n",
    "    #Добавление этого фактора(длина строки отзыва )  ухудшала MAE поэтому от него отказался \n",
    "    df_output['lenght_reviews'] = df_output['Reviews'].apply(get_lenght_reviews)\n",
    "    \n",
    "    #pf = PolynomialFeatures(2)\n",
    "    #df_output['delta_today_reviews_last_date'].fillna(0).astype('float')\n",
    "    #df_output['delta_last_date_first_date'].fillna(0).astype('float')        \n",
    "    #pf.fit_transform(df_output[['delta_today_reviews_last_date', 'delta_last_date_first_date']])\n",
    "    #df_output[['delta_today_reviews_last_date', 'delta_last_date_first_date']] = pf.fit_transform(df_output[['delta_today_reviews_last_date', 'delta_last_date_first_date']])\n",
    "        \n",
    "    #Для дальнейшего удаления колонок изменим тип на object    \n",
    "    df_output['Reviews_first_date'] = df_output['Reviews_first_date'].astype('str')\n",
    "    df_output['Reviews_last_date']  = df_output['Reviews_last_date'].astype('str')\n",
    "    df_output['datetime_today']     = df_output['datetime_today'].astype('str')\n",
    "    \n",
    "    \n",
    "    #df_output = df_output.fillna(0)\n",
    "    #df_output = df_output.fillna(df_output.median())\n",
    "    \n",
    "    # ################### 5. Clean #################################################### \n",
    "    # убираем признаки которые еще не успели обработать, \n",
    "    # модель на признаках с dtypes \"object\" обучаться не будет, просто выберим их и удалим\n",
    "    object_columns = [s for s in df_output.columns if df_output[s].dtypes == 'object']\n",
    "    df_output.drop(object_columns, axis = 1, inplace=True)\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">По хорошему, можно было бы перевести эту большую функцию в класс и разбить на подфункции (согласно ООП). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Запускаем и проверяем что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc = preproc_data(data)\n",
    "df_preproc.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_info_column(df_preproc, 'delta_today_reviews_last_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбросы оставлю как есть если удалить теряется много данных, а если их заполнить другими значениями то ухудшается MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_info_column(df_preproc, 'delta_last_date_first_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбросы оставлю как есть если удалить теряется много данных, а если их заполнить другими значениями то ухудшается MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_info_column(df_preproc, 'count_cuisine_style')\n",
    "#df_preproc.loc[(df_preproc['delta_last_date_first_date']<0) | (df_preproc['delta_last_date_first_date']>1871)] = df_preproc['delta_today_reviews_last_dat'].median()\n",
    "#df_preproc.loc[(df_preproc['delta_last_date_first_date']<0)] = 0#df_preproc['delta_last_date_first_date'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбросы оставлю как есть если удалить теряется много данных, а если их заполнить другими значениями то ухудшается MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_preproc.loc[(df_preproc['count_cuisine_style']>4)] = df_preproc['count_cuisine_style'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc = df_preproc.fillna(df_preproc.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь выделим тестовую часть\n",
    "train_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n",
    "\n",
    "y = train_data.Rating.values            # наш таргет\n",
    "X = train_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \n",
    "Это поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n",
    "# выделим 20% данных на валидацию (параметр test_size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем\n",
    "test_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "Сам ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\n",
    "model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель на тестовом наборе данных\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Если все устраевает - готовим Submission на кагл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['Rating'] = predict_submission\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's next?\n",
    "Или что делать, чтоб улучшить результат:\n",
    "* Обработать оставшиеся признаки в понятный для машины формат\n",
    "* Посмотреть, что еще можно извлечь из признаков\n",
    "* Сгенерировать новые признаки\n",
    "* Подгрузить дополнительные данные, например: по населению или благосостоянию городов\n",
    "* Подобрать состав признаков\n",
    "\n",
    "В общем, процесс творческий и весьма увлекательный! Удачи в соревновании!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle competitions submit -c sf-dst-restaurant-rating -f submission.csv -m \"Message\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
